{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy.stats as stat\n",
    "\n",
    "from math import sqrt\n",
    "from mlgear.utils import show, display_columns\n",
    "from surveyweights import normalize_weights\n",
    "from survey_dud_detector import detect_straightlining\n",
    "\n",
    "\n",
    "def margin_of_error(n=None, sd=None, p=None, type='proportion', interval_size=0.95):\n",
    "    z_lookup = {0.8: 1.28, 0.85: 1.44, 0.9: 1.65, 0.95: 1.96, 0.99: 2.58}\n",
    "    if interval_size not in z_lookup.keys():\n",
    "        raise ValueError('{} not a valid `interval_size` - must be {}'.format(interval_size,\n",
    "                                                                              ', '.join(list(z_lookup.keys()))))\n",
    "    if type == 'proportion':\n",
    "        se = sqrt(p * (1 - p)) / sqrt(n)\n",
    "    elif type == 'continuous':\n",
    "        se = sd / sqrt(n)\n",
    "    else:\n",
    "        raise ValueError('{} not a valid `type` - must be proportion or continuous')\n",
    "    \n",
    "    z = z_lookup[interval_size]\n",
    "    return se * z\n",
    "\n",
    "\n",
    "def print_pct(pct, digits=0):\n",
    "    pct = pct * 100\n",
    "    pct = np.round(pct, digits)\n",
    "    if pct >= 100:\n",
    "        if digits == 0:\n",
    "            val = '>99.0%'\n",
    "        else:\n",
    "            val = '>99.'\n",
    "            for d in range(digits - 1):\n",
    "                val += '9'\n",
    "            val += '9%'\n",
    "    elif pct <= 0:\n",
    "        if digits == 0:\n",
    "            val = '<0.1%'\n",
    "        else:\n",
    "            val = '<0.'\n",
    "            for d in range(digits - 1):\n",
    "                val += '0'\n",
    "            val += '1%'\n",
    "    else:\n",
    "        val = '{}%'.format(pct)\n",
    "    return val\n",
    "\n",
    "\n",
    "def calc_result(for_vote, against_vote, n, interval=0.8):\n",
    "    GENERAL_POLLING_ERROR = 4.0\n",
    "    ACQUIESENCE_BIAS = -5.0\n",
    "    N_SIMS = 10000000\n",
    "    \n",
    "    for_moe = margin_of_error(n=n, p=for_vote/100, interval_size=interval)\n",
    "    against_moe = margin_of_error(n=n, p=against_vote/100, interval_size=interval)\n",
    "    undecided = 100 - for_vote - against_vote\n",
    "    mean = for_vote + undecided * 0.25 + ACQUIESENCE_BIAS\n",
    "    raw_moe = for_moe * 100 + against_moe * 100\n",
    "    \n",
    "    allocate_undecided = undecided * 0.4\n",
    "    margin = raw_moe + allocate_undecided + GENERAL_POLLING_ERROR\n",
    "    \n",
    "    cdf_value = 0.5 + 0.5 * interval\n",
    "    normed_sigma = stat.norm.ppf(cdf_value)\n",
    "    sigma = margin / 100 / normed_sigma\n",
    "    \n",
    "    sims = np.random.normal(mean / 100, sigma, N_SIMS)\n",
    "    chance_pass = np.sum([s > 0.5 for s in sims]) / N_SIMS\n",
    "    low, high = np.percentile(sims, [20, 80]) * 100\n",
    "    \n",
    "    return {'mean': mean, 'high': high, 'low': low, 'n': n,\n",
    "            'raw_moe': raw_moe, 'margin': margin, 'sigma': sigma, 'chance_pass': chance_pass}\n",
    "\n",
    "\n",
    "def print_result(mean, high, low, n, raw_moe, margin, sigma, chance_pass):\n",
    "    mean = np.round(mean, 1)\n",
    "    first = np.round(high, 1)\n",
    "    second = np.round(low, 1)\n",
    "    sigma = np.round(sigma * 100, 1)\n",
    "    raw_moe = np.round(raw_moe, 1)\n",
    "    margin = np.round(margin, 1)\n",
    "    chance_pass = print_pct(chance_pass, 1)\n",
    "    if second < first:\n",
    "        _ = first\n",
    "        first = second\n",
    "        second = _\n",
    "    if second > 100:\n",
    "        second = 100\n",
    "    if first < 0:\n",
    "        first = 0\n",
    "    print(('Result {} (80% CI: {} to {}) (N={}) (raw_moe={}pts, margin={}pts, '\n",
    "           'sigma={}pts) ({} likely to pass)').format(mean,\n",
    "                                                      first,\n",
    "                                                      second,\n",
    "                                                      n,\n",
    "                                                      raw_moe,\n",
    "                                                      margin,\n",
    "                                                      sigma,\n",
    "                                                      chance_pass))\n",
    "    print(('{} (80% CI: {} to {}) ({})').format(mean,\n",
    "                                                first,\n",
    "                                                second,\n",
    "                                                chance_pass))\n",
    "    print('-')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Processed Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/peterhurford/.virtualenvs/dev/lib/python3.8/site-packages/IPython/core/interactiveshell.py:3145: DtypeWarning: Columns (9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,40,41,42,43,90,91,92,93,94,95,96,97,98,99,100,101,102,103,104,105,106,107,108,109,110,111,112) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n"
     ]
    }
   ],
   "source": [
    "survey = pd.read_csv('responses_processed_national_weighted.csv').fillna('Not presented')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Insect Proposition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "## vote_measure_no_insect_feed NATIONAL WEIGHTED ##\n",
      "Vote for / Support        27.200648\n",
      "Vote against / Oppose     49.946462\n",
      "Don’t know / Undecided    22.852890\n",
      "dtype: float64\n",
      "Result 27.9 (80% CI: 14.9 to 40.9) (N=334) (raw_moe=6.6pts, margin=19.8pts, sigma=15.4pts) (7.6% likely to pass)\n",
      "27.9 (80% CI: 14.9 to 40.9) (7.6%)\n",
      "-\n",
      "## vote_measure_no_insect_feed NATIONAL WEIGHTED + LV ##\n",
      "Vote for / Support        28.507542\n",
      "Vote against / Oppose     48.907861\n",
      "Don’t know / Undecided    22.584597\n",
      "dtype: float64\n",
      "Result 29.2 (80% CI: 16.1 to 42.2) (N=311) (raw_moe=6.9pts, margin=19.9pts, sigma=15.6pts) (9.0% likely to pass)\n",
      "29.2 (80% CI: 16.1 to 42.2) (9.0%)\n",
      "-\n",
      "## vote_measure_no_insect_feed NATIONAL WEIGHTED, EXTRA ADJUSTED + LV ##\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'voted2016'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m~/.virtualenvs/dev/lib/python3.8/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   2894\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2895\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2896\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'voted2016'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-7f21ee1d08bb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'## vote_measure_no_insect_feed NATIONAL WEIGHTED, EXTRA ADJUSTED + LV ##'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m \u001b[0msurvey_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m~\u001b[0m\u001b[0msurvey_\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'voted2016'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m&\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0msurvey\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'vote_trump_biden'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'Donald Trump, the Republican'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'lv_weight'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m*=\u001b[0m \u001b[0;36m1.7\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m \u001b[0mlv_weighted_n\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mround\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msurvey_\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'lv_weight'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mw\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mw\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0mvotes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msurvey_\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'vote_measure_no_insect_feed'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue_counts\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnormalize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0msurvey_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroupby\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'vote_measure_no_insect_feed'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'lv_weight'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/dev/lib/python3.8/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   2900\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnlevels\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2901\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2902\u001b[0;31m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2903\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_integer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2904\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/dev/lib/python3.8/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   2895\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2896\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2897\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2898\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2899\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtolerance\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'voted2016'"
     ]
    }
   ],
   "source": [
    "options = ['Vote for / Support', 'Vote against / Oppose', 'Don’t know / Undecided']\n",
    "\n",
    "survey_ = survey.loc[survey['vote_measure_no_insect_feed'].isin(options)].copy()\n",
    "survey_['weight'] = normalize_weights(survey_['weight'])\n",
    "survey_['rv_weight'] = normalize_weights(survey_['rv_weight'])\n",
    "survey_['lv_weight'] = normalize_weights(survey_['lv_weight'])\n",
    "\n",
    "print('## vote_measure_no_insect_feed NATIONAL WEIGHTED ##')\n",
    "lv_weighted_n = int(np.round(survey_['weight'].apply(lambda w: 1 if w > 1 else w).sum()))\n",
    "votes = survey_['vote_measure_no_insect_feed'].value_counts(normalize=True) * survey_.groupby('vote_measure_no_insect_feed')['weight'].mean() * 100\n",
    "votes = votes[options] * (100 / votes[options].sum())\n",
    "print(votes)\n",
    "print_result(**calc_result(for_vote=votes['Vote for / Support'],\n",
    "                           against_vote=votes['Vote against / Oppose'],\n",
    "                           n=lv_weighted_n))\n",
    "\n",
    "print('## vote_measure_no_insect_feed NATIONAL WEIGHTED + LV ##')\n",
    "lv_weighted_n = int(np.round(survey_['lv_weight'].apply(lambda w: 1 if w > 1 else w).sum()))\n",
    "votes = survey_['vote_measure_no_insect_feed'].value_counts(normalize=True) * survey_.groupby('vote_measure_no_insect_feed')['lv_weight'].mean() * 100\n",
    "votes = votes[options] * (100 / votes[options].sum())\n",
    "print(votes)\n",
    "print_result(**calc_result(for_vote=votes['Vote for / Support'],\n",
    "                           against_vote=votes['Vote against / Oppose'],\n",
    "                           n=lv_weighted_n))\n",
    "\n",
    "print('## vote_measure_no_insect_feed NATIONAL WEIGHTED, EXTRA ADJUSTED + LV ##')\n",
    "survey_.loc[(~survey_['voted2016']) & (survey['vote_trump_biden'] == 'Donald Trump, the Republican'), 'lv_weight'] *= 1.7\n",
    "lv_weighted_n = int(np.round(survey_['lv_weight'].apply(lambda w: 1 if w > 1 else w).sum()))\n",
    "votes = survey_['vote_measure_no_insect_feed'].value_counts(normalize=True) * survey_.groupby('vote_measure_no_insect_feed')['lv_weight'].mean() * 100\n",
    "votes = votes[options] * (100 / votes[options].sum())\n",
    "print(votes)\n",
    "print_result(**calc_result(for_vote=votes['Vote for / Support'],\n",
    "                           against_vote=votes['Vote against / Oppose'],\n",
    "                           n=lv_weighted_n))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Insect Feed Attitudes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "questions = {'agree_flies_animal_feed': 'How much do you agree or disagree with the following?: Flies are a suitable source of protein for use in animal feed',\n",
    "            'agree_eat_animals_fed_insects': 'How much do you agree or disagree with the following?: I would eat meat if I knew it the animal had been fed insects as part of its feed',\n",
    "            'agree_eat_insects': 'How much do you agree or disagree with the following?: I would never personally eat insects',\n",
    "            'agree_flies_animal_feed_alt': 'How much do you agree or disagree with the following?: It is acceptable to feed insects to animals that are raised for food',\n",
    "            'agree_eat_animals_fed_insects_alt_reverse': 'How much do you agree or disagree with the following?: I would not be comfortable eating meat from an animal that was raised on insect feed',\n",
    "            'agree_insect_feed_harms_health': 'How much do you agree or disagree with the following?: Eating meat from an animal that was raised on feed made from insects poses a risk to human health'}\n",
    "\n",
    "options = ['Agree', 'Disagree', 'Don\\'t know']\n",
    "\n",
    "for var, question in questions.items():\n",
    "    print('## {} ##'.format(question))\n",
    "    survey_ = survey.loc[survey[var].isin(options)].copy()\n",
    "    survey_['weight'] = normalize_weights(survey_['weight'])\n",
    "    print(survey_[var].value_counts(normalize=True) * survey_.groupby(var)['weight'].mean() * 100)\n",
    "    print('-')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "straightlining_flies = detect_straightlining(survey[[c for c in survey.columns if 'agree_flies' in c or 'agree_eat' in c or 'agree_insects' in c]])\n",
    "survey['meta_straightlining_flies'] = straightlining_flies\n",
    "survey['meta_straightlining_flies'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.crosstab(survey['agree_flies_animal_feed'], survey['agree_flies_animal_feed_alt'])\n",
    "# Flies are a suitable source of protein for use in animal feed\n",
    "# It is acceptable to feed insects to animals that are raised for food"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.crosstab(survey['agree_eat_animals_fed_insects'], survey['agree_eat_animals_fed_insects_alt_reverse'])\n",
    "# I would eat meat if I knew it the animal had been fed insects as part of its feed\n",
    "# I would not be comfortable eating meat from an animal that was raised on insect feed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "survey.loc[:, 'flies_comprehension'] = 1\n",
    "survey.loc[survey['agree_flies_animal_feed'] == 'Don\\'t know', 'flies_comprehension'] = -1\n",
    "survey.loc[survey['agree_flies_animal_feed'] == 'Not presented', 'flies_comprehension'] = -2\n",
    "survey.loc[survey['agree_flies_animal_feed_alt'] == 'Don\\'t know', 'flies_comprehension'] = 0\n",
    "survey.loc[survey['agree_flies_animal_feed_alt'] == 'Not presented', 'flies_comprehension'] = -2\n",
    "survey.loc[(survey['agree_flies_animal_feed'] == 'Agree') & (survey['agree_flies_animal_feed_alt'] == 'Disagree'), 'flies_comprehension'] = 0\n",
    "survey.loc[(survey['agree_flies_animal_feed'] == 'Disgree') & (survey['agree_flies_animal_feed_alt'] == 'Agree'), 'flies_comprehension'] = 0\n",
    "\n",
    "survey.loc[survey['agree_eat_animals_fed_insects'] == 'Don\\'t know', 'flies_comprehension'] = -1\n",
    "survey.loc[survey['agree_eat_animals_fed_insects'] == 'Not presented', 'flies_comprehension'] = -2\n",
    "survey.loc[survey['agree_eat_animals_fed_insects_alt_reverse'] == 'Don\\'t know', 'flies_comprehension'] = -1\n",
    "survey.loc[survey['agree_eat_animals_fed_insects_alt_reverse'] == 'Not presented', 'flies_comprehension'] = -2\n",
    "survey.loc[(survey['flies_comprehension'] >= 0) & (survey['agree_eat_animals_fed_insects'] == 'Agree') & (survey['agree_eat_animals_fed_insects_alt_reverse'] == 'Agree'), 'flies_comprehension'] = 0\n",
    "survey.loc[(survey['flies_comprehension'] >= 0) & (survey['agree_eat_animals_fed_insects'] == 'Disagree') & (survey['agree_eat_animals_fed_insects_alt_reverse'] == 'Disagree'), 'flies_comprehension'] = 0\n",
    "\n",
    "survey['flies_comprehension'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.crosstab(survey['flies_comprehension'], survey['meta_straightlining_flies'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Animal Pain Attitudes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "options = ['Agree', 'Disagree', 'Don\\'t know']\n",
    "\n",
    "for c in survey.columns:\n",
    "    if 'agree_pain' in c:\n",
    "        print('## {} ##'.format(c))\n",
    "        survey_ = survey.loc[survey[var].isin(options)].copy()\n",
    "        survey_['weight'] = normalize_weights(survey_['weight'])\n",
    "        print(survey_[c].value_counts(normalize=True) * survey_.groupby(c)['weight'].mean() * 100)\n",
    "        print('-')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "straightlining_pain = detect_straightlining(survey[[c for c in survey.columns if 'agree_pain' in c]])\n",
    "straightlining_pain.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.crosstab(survey['agree_pain_ants'], survey['agree_flies_animal_feed'], normalize='index')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
